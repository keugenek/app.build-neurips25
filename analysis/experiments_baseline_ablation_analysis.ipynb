{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Human Evaluation Analysis: Baseline vs Ablations\n",
        "\n",
        "This notebook analyzes the **human-evaluated results** from the app.build benchmark.\n",
        "\n",
        "**Data Source**: Manual evaluation CSV files containing:\n",
        "- Human assessments with PASS/WARN/FAIL/NA values for each AB check\n",
        "- Evaluator assignments (A1/A2)\n",
        "- Performance scores and detailed notes\n",
        "\n",
        "**For automated test results**, see `automated_results_analysis.ipynb`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading from Human-Evaluated CSV Files\n",
        "\n",
        "Loading data from the actual human-evaluated CSV files that contain AB column evaluations with PASS/WARN/FAIL/NA values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded:\n",
            "- Baseline cases: 30\n",
            "- baseline: 30 cases\n",
            "- no_lint: 30 cases\n",
            "- no_playwright: 30 cases\n",
            "- no_tests: 30 cases\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display options\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "# Use human-evaluated CSV files from analysis directory\n",
        "ANALYSIS_DIR = Path(\".\") if Path(\"app.build-neurips25 - baseline.csv\").exists() else Path(\"/Users/evgenii.kniazev/projects/app.build-neurips25/analysis\")\n",
        "\n",
        "# Map ablation names to their CSV files\n",
        "FILES = {\n",
        "    \"baseline\": ANALYSIS_DIR / \"app.build-neurips25 - baseline.csv\",\n",
        "    \"no_lint\": ANALYSIS_DIR / \"app.build-neurips25 - ablations_no_lint.csv\",\n",
        "    \"no_playwright\": ANALYSIS_DIR / \"app.build-neurips25 - ablations_no_playwright.csv\",\n",
        "    \"no_tests\": ANALYSIS_DIR / \"app.build-neurips25 - ablations_no_tests.csv\",\n",
        "}\n",
        "\n",
        "# Canonical AB columns (ASCII hyphen)\n",
        "AB_COLUMNS = [\n",
        "    \"AB-01 Boot\",\n",
        "    \"AB-02 Prompt\",\n",
        "    \"AB-03 Create\",\n",
        "    \"AB-04 View/Edit\",\n",
        "    \"AB-06 Clickable Sweep\",\n",
        "    \"AB-07 Performance >75\",\n",
        "]\n",
        "\n",
        "# Normalize AB column names (unify hyphens and drop AB-05 if present)\n",
        "AB_NORMALIZE = {\n",
        "    # 01-04 variants → ASCII hyphen\n",
        "    \"AB–01 Boot\": \"AB-01 Boot\",\n",
        "    \"AB—01 Boot\": \"AB-01 Boot\",\n",
        "    \"AB‑01 Boot\": \"AB-01 Boot\",\n",
        "    \"AB‑02 Prompt\": \"AB-02 Prompt\",\n",
        "    \"AB–02 Prompt\": \"AB-02 Prompt\",\n",
        "    \"AB—02 Prompt\": \"AB-02 Prompt\",\n",
        "    \"AB‑03 Create\": \"AB-03 Create\",\n",
        "    \"AB‑04 View/Edit\": \"AB-04 View/Edit\",\n",
        "    # 06/07 variants → ASCII hyphen\n",
        "    \"AB‑06 Clickable Sweep\": \"AB-06 Clickable Sweep\",\n",
        "    \"AB–06 Clickable Sweep\": \"AB-06 Clickable Sweep\",\n",
        "    \"AB—06 Clickable Sweep\": \"AB-06 Clickable Sweep\",\n",
        "    \"AB‑07 Performance >75\": \"AB-07 Performance >75\",\n",
        "    \"AB–07 Performance >75\": \"AB-07 Performance >75\",\n",
        "    \"AB—07 Performance >75\": \"AB-07 Performance >75\",\n",
        "    # Drop AB-05 if present\n",
        "    \"AB-05 UI Sweep\": None,\n",
        "    \"AB‑05 UI Sweep\": None,\n",
        "}\n",
        "\n",
        "AGG_COLUMNS = [\"PASS#\", \"WARN#\", \"FAIL#\"]\n",
        "KEY_COLUMN = \"Case\"\n",
        "\n",
        "STATUS_ORDER = [\"FAIL\", \"WARN\", \"NA\", \"PASS\"]  # ordered for ordinal mapping\n",
        "STATUS_TO_SCORE = {\"FAIL\": 0, \"WARN\": 0.5, \"NA\": np.nan, \"PASS\": 1.0}\n",
        "\n",
        "\n",
        "def normalize_ab_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # unify column names and drop AB-05 variants\n",
        "    rename_map = {c: AB_NORMALIZE[c] for c in df.columns if c in AB_NORMALIZE and AB_NORMALIZE[c]}\n",
        "    df = df.rename(columns=rename_map)\n",
        "    drop_cols = [c for c in df.columns if c in AB_NORMALIZE and AB_NORMALIZE[c] is None]\n",
        "    if drop_cols:\n",
        "        df = df.drop(columns=drop_cols)\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_csv(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    # unify column names (strip spaces) and types\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # These are human-evaluated CSV files - normalize AB naming\n",
        "    df = normalize_ab_columns(df)\n",
        "\n",
        "    # ensure any missing AB columns exist (fill with 'NA' so analysis can proceed)\n",
        "    missing = [c for c in AB_COLUMNS if c not in df.columns]\n",
        "    if missing:\n",
        "        print(f\"Warning: Missing AB columns in {path.name}: {missing}. Filling with 'NA'.\")\n",
        "        for c in missing:\n",
        "            df[c] = \"NA\"\n",
        "\n",
        "    # ensure numeric columns are numeric\n",
        "    for col in AGG_COLUMNS:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    # key normalization\n",
        "    df[KEY_COLUMN] = df[KEY_COLUMN].astype(str)\n",
        "    return df\n",
        "\n",
        "\n",
        "def score_status_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    scored = df.copy()\n",
        "    for col in AB_COLUMNS:\n",
        "        if col in scored.columns:\n",
        "            scored[f\"{col}__score\"] = scored[col].map(STATUS_TO_SCORE)\n",
        "        else:\n",
        "            scored[f\"{col}__score\"] = np.nan\n",
        "    scored[\"AB_mean_score\"] = scored[[f\"{c}__score\" for c in AB_COLUMNS]].mean(axis=1, skipna=True)\n",
        "    return scored\n",
        "\n",
        "\n",
        "# Load all datasets\n",
        "raw: Dict[str, pd.DataFrame] = {k: load_csv(v) for k, v in FILES.items()}\n",
        "scored: Dict[str, pd.DataFrame] = {k: score_status_columns(df) for k, df in raw.items()}\n",
        "\n",
        "# Align on common cases present in baseline for fair comparison\n",
        "baseline_cases = set(scored[\"baseline\"][KEY_COLUMN])\n",
        "for k in list(scored.keys()):\n",
        "    scored[k] = scored[k][scored[k][KEY_COLUMN].isin(baseline_cases)].reset_index(drop=True)\n",
        "\n",
        "print(\"Datasets loaded:\")\n",
        "print(f\"- Baseline cases: {len(baseline_cases)}\")\n",
        "for k, v in scored.items():\n",
        "    print(f\"- {k}: {len(v)} cases\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Viability and Quality Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Human Evaluation Summary:\n",
            "baseline: Viability=73.3%, Mean Q=8.1\n",
            "no_lint: Viability=80.0%, Mean Q=8.3\n",
            "no_playwright: Viability=90.0%, Mean Q=8.6\n",
            "no_tests: Viability=80.0%, Mean Q=7.8\n"
          ]
        }
      ],
      "source": [
        "# Compute Viability (V) and Quality (Q) per new spec\n",
        "\n",
        "GATE_FAIL_COLUMNS = [\"AB-01 Boot\", \"AB-02 Prompt\"]\n",
        "\n",
        "# Equal weights across AB checks; NA re-normalization happens via mean with skipna\n",
        "QUALITY_MAP = {\n",
        "    \"AB-01 Boot\": {\"PASS\": 1.0, \"WARN\": 0.5, \"FAIL\": 0.0, \"NA\": np.nan},\n",
        "    \"AB-02 Prompt\": {\"PASS\": 1.0, \"WARN\": 0.5, \"FAIL\": 0.0, \"NA\": np.nan},\n",
        "    \"AB-03 Create\": {\"PASS\": 1.0, \"WARN\": 0.5, \"FAIL\": 0.0, \"NA\": np.nan},\n",
        "    \"AB-04 View/Edit\": {\"PASS\": 1.0, \"WARN\": 0.5, \"FAIL\": 0.0, \"NA\": np.nan},\n",
        "    \"AB-06 Clickable Sweep\": {\"PASS\": 1.0, \"WARN\": 0.5, \"FAIL\": 0.0, \"NA\": np.nan},\n",
        "    # AB-07 Performance >75 is a binary proxy of performance; map as before for legacy CSVs\n",
        "    \"AB-07 Performance >75\": {\"PASS\": 1.0, \"WARN\": 0.5, \"FAIL\": 0.0, \"NA\": np.nan},\n",
        "}\n",
        "\n",
        "\n",
        "def compute_viability(row: pd.Series) -> int:\n",
        "    for col in GATE_FAIL_COLUMNS:\n",
        "        if col in row and str(row[col]) == \"FAIL\":\n",
        "            return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def compute_quality(row: pd.Series) -> float:\n",
        "    scores = []\n",
        "    for col, mapping in QUALITY_MAP.items():\n",
        "        if col in row:\n",
        "            scores.append(mapping.get(str(row[col]), np.nan))\n",
        "    if len(scores) == 0:\n",
        "        return np.nan\n",
        "    return float(np.nanmean(scores) * 10.0)\n",
        "\n",
        "# Apply to all datasets\n",
        "for k in list(scored.keys()):\n",
        "    df = scored[k]\n",
        "    scored[k][\"V\"] = df.apply(compute_viability, axis=1)\n",
        "    scored[k][\"Q\"] = df.apply(compute_quality, axis=1)\n",
        "\n",
        "# Quick sanity: show mean Q and viability rate per table\n",
        "print(\"\\nHuman Evaluation Summary:\")\n",
        "for k, stats in { k: {\"mean_Q\": float(scored[k][\"Q\"].mean()), \"viability_rate\": float(scored[k][\"V\"].mean())} for k in scored }.items():\n",
        "    print(f\"{k}: Viability={stats['viability_rate']:.1%}, Mean Q={stats['mean_Q']:.1f}\")\n",
        "\n",
        "# Also show a complete summary table\n",
        "summary_rows: List[Dict[str, object]] = []\n",
        "for k in scored:\n",
        "    df = scored[k]\n",
        "    viable_df = df[df[\"V\"] == 1]\n",
        "    summary_rows.append({\n",
        "        \"Ablation\": k.replace(\"_\", \" \").title(),\n",
        "        \"N\": len(df),\n",
        "        \"Viability\": f\"{df['V'].mean():.1%}\",\n",
        "        \"Viable Count\": int(df['V'].sum()),\n",
        "        \"Mean Q (all)\": f\"{df['Q'].mean():.1f}\",\n",
        "        \"Mean Q (viable)\": f\"{viable_df['Q'].mean():.1f}\" if len(viable_df) > 0 else \"N/A\",\n",
        "    })\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "try:\n",
        "    display(summary_df)\n",
        "except Exception:\n",
        "    print(summary_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Performance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Performance (n=30):\n",
            "- Viability rate: 73.3% (22/30 apps)\n",
            "- Quality scores:\n",
            "  • Overall mean: 8.1\n",
            "  • Viable apps only: 9.6\n",
            "\n",
            "Quality distribution for viable apps:\n",
            "  Q=7.5: █ (1 apps)\n",
            "  Q=8.3: █ (1 apps)\n",
            "  Q=8.8: █ (1 apps)\n",
            "  Q=9.0: █ (1 apps)\n",
            "  Q=9.2: ████ (4 apps)\n",
            "  Q=10.0: ██████████████ (14 apps)\n"
          ]
        }
      ],
      "source": [
        "# Baseline summary\n",
        "base = scored[\"baseline\"].copy()\n",
        "viable = base[base['V']==1]\n",
        "\n",
        "print(f\"Baseline Performance (n={len(base)}):\")\n",
        "print(f\"- Viability rate: {base['V'].mean():.1%} ({int(base['V'].sum())}/{len(base)} apps)\")\n",
        "print(f\"- Quality scores:\")\n",
        "print(f\"  • Overall mean: {base['Q'].mean():.1f}\")\n",
        "print(f\"  • Viable apps only: {viable['Q'].mean():.1f}\")\n",
        "print(f\"\\nQuality distribution for viable apps:\")\n",
        "q_dist = viable['Q'].value_counts().sort_index()\n",
        "for q_val, count in q_dist.items():\n",
        "    print(f\"  Q={q_val:.1f}: {'█' * count} ({count} apps)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Human Evaluation: Ablation Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== HUMAN EVALUATION ABLATION COMPARISON ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ablation</th>\n",
              "      <th>N</th>\n",
              "      <th>Viability</th>\n",
              "      <th>Viable Count</th>\n",
              "      <th>Mean Q (all)</th>\n",
              "      <th>Mean Q (viable)</th>\n",
              "      <th>Δ Viability</th>\n",
              "      <th>Δ Quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline</td>\n",
              "      <td>30</td>\n",
              "      <td>73.3%</td>\n",
              "      <td>22</td>\n",
              "      <td>8.1</td>\n",
              "      <td>9.6</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No Lint</td>\n",
              "      <td>30</td>\n",
              "      <td>80.0%</td>\n",
              "      <td>24</td>\n",
              "      <td>8.3</td>\n",
              "      <td>9.3</td>\n",
              "      <td>+6.7%</td>\n",
              "      <td>+0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No Playwright</td>\n",
              "      <td>30</td>\n",
              "      <td>90.0%</td>\n",
              "      <td>27</td>\n",
              "      <td>8.6</td>\n",
              "      <td>9.4</td>\n",
              "      <td>+16.7%</td>\n",
              "      <td>+0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No Tests</td>\n",
              "      <td>30</td>\n",
              "      <td>80.0%</td>\n",
              "      <td>24</td>\n",
              "      <td>7.8</td>\n",
              "      <td>9.3</td>\n",
              "      <td>+6.7%</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Ablation   N Viability  Viable Count Mean Q (all) Mean Q (viable)  \\\n",
              "0       Baseline  30     73.3%            22          8.1             9.6   \n",
              "1        No Lint  30     80.0%            24          8.3             9.3   \n",
              "2  No Playwright  30     90.0%            27          8.6             9.4   \n",
              "3       No Tests  30     80.0%            24          7.8             9.3   \n",
              "\n",
              "  Δ Viability Δ Quality  \n",
              "0           -         -  \n",
              "1       +6.7%      +0.2  \n",
              "2      +16.7%      +0.6  \n",
              "3       +6.7%      -0.3  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Impact Analysis ===\n",
            "\n",
            "No Lint:\n",
            "  - Viability: 80.0% (+6.7% from baseline)\n",
            "  - Quality: 8.3 (+0.2 from baseline)\n",
            "  - Major changes: AB-03 Create: -6.7%, AB-04 View/Edit: -13.3%, AB-07 Performance >75: +10.0%\n",
            "\n",
            "No Playwright:\n",
            "  - Viability: 90.0% (+16.7% from baseline)\n",
            "  - Quality: 8.6 (+0.6 from baseline)\n",
            "  - Major changes: AB-02 Prompt: +13.3%, AB-03 Create: +6.7%, AB-04 View/Edit: +6.7%, AB-06 Clickable Sweep: +13.3%, AB-07 Performance >75: +10.0%\n",
            "\n",
            "No Tests:\n",
            "  - Viability: 80.0% (+6.7% from baseline)\n",
            "  - Quality: 7.8 (-0.3 from baseline)\n",
            "  - Major changes: AB-03 Create: -6.7%, AB-04 View/Edit: -20.0%, AB-06 Clickable Sweep: +6.7%\n"
          ]
        }
      ],
      "source": [
        "# Compare all ablations\n",
        "comparison_data = []\n",
        "for k in [\"baseline\", \"no_lint\", \"no_playwright\", \"no_tests\"]:\n",
        "    df = scored[k]\n",
        "    viable_df = df[df['V']==1]\n",
        "    \n",
        "    comparison_data.append({\n",
        "        \"Ablation\": k.replace(\"_\", \" \").title(),\n",
        "        \"N\": len(df),\n",
        "        \"Viability\": f\"{df['V'].mean():.1%}\",\n",
        "        \"Viable Count\": int(df['V'].sum()),\n",
        "        \"Mean Q (all)\": f\"{df['Q'].mean():.1f}\",\n",
        "        \"Mean Q (viable)\": f\"{viable_df['Q'].mean():.1f}\" if len(viable_df) > 0 else \"N/A\",\n",
        "        \"Δ Viability\": f\"{(df['V'].mean() - scored['baseline']['V'].mean())*100:+.1f}%\" if k != \"baseline\" else \"-\",\n",
        "        \"Δ Quality\": f\"{(df['Q'].mean() - scored['baseline']['Q'].mean()):+.1f}\" if k != \"baseline\" else \"-\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\n=== HUMAN EVALUATION ABLATION COMPARISON ===\")\n",
        "try:\n",
        "    display(comparison_df)\n",
        "except Exception:\n",
        "    print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Statistical analysis\n",
        "print(\"\\n=== Impact Analysis ===\")\n",
        "baseline_v = scored['baseline']['V'].mean()\n",
        "baseline_q = scored['baseline']['Q'].mean()\n",
        "\n",
        "for k in [\"no_lint\", \"no_playwright\", \"no_tests\"]:\n",
        "    df = scored[k]\n",
        "    v_rate = df['V'].mean()\n",
        "    q_mean = df['Q'].mean()\n",
        "    \n",
        "    print(f\"\\n{k.replace('_', ' ').title()}:\")\n",
        "    print(f\"  - Viability: {v_rate:.1%} ({(v_rate - baseline_v)*100:+.1f}% from baseline)\")\n",
        "    print(f\"  - Quality: {q_mean:.1f} ({q_mean - baseline_q:+.1f} from baseline)\")\n",
        "    \n",
        "    # Check which AB columns changed most\n",
        "    ab_changes = []\n",
        "    for col in AB_COLUMNS:\n",
        "        baseline_pass = (scored['baseline'][col] == \"PASS\").mean()\n",
        "        ablation_pass = (df[col] == \"PASS\").mean()\n",
        "        if abs(ablation_pass - baseline_pass) > 0.05:  # >5% change\n",
        "            ab_changes.append(f\"{col}: {(ablation_pass - baseline_pass)*100:+.1f}%\")\n",
        "    \n",
        "    if ab_changes:\n",
        "        print(f\"  - Major changes: {', '.join(ab_changes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
