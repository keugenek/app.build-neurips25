{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline vs Ablations: Check Impact Analysis\n",
        "\n",
        "This notebook analyzes the baseline experiment results against ablation runs where certain checks were disabled. It focuses on how the outcome of the same experiments changed when the following checks were turned off:\n",
        "\n",
        "- no_lint\n",
        "- no_tests\n",
        "- no_playwright\n",
        "\n",
        "Data sources are CSV files in `analysis/` with a common schema:\n",
        "- Case identifier and Assignee\n",
        "- AB-xx check columns with values in {PASS, WARN, FAIL, NA}\n",
        "- Aggregate columns: `PASS#`, `WARN#`, `FAIL#`, `PTS`\n",
        "- Free-text `Notes`\n",
        "\n",
        "We will:\n",
        "- Load and clean the datasets\n",
        "- Summarize the baseline\n",
        "- Compare each ablation to baseline with per-case deltas and aggregate trends\n",
        "- Visualize mean deltas and surface the largest regressions and improvements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display options\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "DATA_DIR = Path(\"/home/eugenek/app.build-neurips25/analysis\")\n",
        "FILES = {\n",
        "    \"baseline\": DATA_DIR / \"app.build-neurips25 - baseline.csv\",\n",
        "    \"no_lint\": DATA_DIR / \"app.build-neurips25 - ablations_no_lint.csv\",\n",
        "    \"no_playwright\": DATA_DIR / \"app.build-neurips25 - ablations_no_playwright.csv\",\n",
        "    \"no_tests\": DATA_DIR / \"app.build-neurips25 - ablations_no_tests.csv\",\n",
        "}\n",
        "\n",
        "AB_COLUMNS = [\n",
        "    \"AB-01 Boot\",\n",
        "    \"AB-02 Prompt\",\n",
        "    \"AB-03 Create\",\n",
        "    \"AB-04 View/Edit\",\n",
        "    \"AB‑06 Clickable Sweep\",\n",
        "    \"AB‑07 Performance >75\",\n",
        "]\n",
        "\n",
        "AGG_COLUMNS = [\"PASS#\", \"WARN#\", \"FAIL#\", \"PTS\"]\n",
        "KEY_COLUMN = \"Case\"\n",
        "\n",
        "STATUS_ORDER = [\"FAIL\", \"WARN\", \"NA\", \"PASS\"]  # ordered for ordinal mapping\n",
        "STATUS_TO_SCORE = {\"FAIL\": 0, \"WARN\": 0.5, \"NA\": np.nan, \"PASS\": 1.0}\n",
        "\n",
        "\n",
        "def load_csv(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    # unify column names (strip spaces) and types\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    # ensure numeric columns are numeric\n",
        "    for col in AGG_COLUMNS:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    # ensure PTS exists; if missing set NaN\n",
        "    if \"PTS\" not in df.columns:\n",
        "        df[\"PTS\"] = np.nan\n",
        "    # key normalization\n",
        "    df[KEY_COLUMN] = df[KEY_COLUMN].astype(str)\n",
        "    return df\n",
        "\n",
        "\n",
        "def score_status_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    scored = df.copy()\n",
        "    for col in AB_COLUMNS:\n",
        "        if col in scored.columns:\n",
        "            scored[f\"{col}__score\"] = scored[col].map(STATUS_TO_SCORE)\n",
        "        else:\n",
        "            scored[f\"{col}__score\"] = np.nan\n",
        "    scored[\"AB_mean_score\"] = scored[[f\"{c}__score\" for c in AB_COLUMNS]].mean(axis=1, skipna=True)\n",
        "    return scored\n",
        "\n",
        "\n",
        "# Load all datasets\n",
        "raw: Dict[str, pd.DataFrame] = {k: load_csv(v) for k, v in FILES.items()}\n",
        "scored: Dict[str, pd.DataFrame] = {k: score_status_columns(df) for k, df in raw.items()}\n",
        "\n",
        "# Align on common cases present in baseline for fair comparison\n",
        "baseline_cases = set(scored[\"baseline\"][KEY_COLUMN])\n",
        "for k in list(scored.keys()):\n",
        "    scored[k] = scored[k][scored[k][KEY_COLUMN].isin(baseline_cases)].reset_index(drop=True)\n",
        "\n",
        "len(baseline_cases), {k: len(v) for k, v in scored.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline summary\n",
        "base = scored[\"baseline\"].copy()\n",
        "\n",
        "# Aggregate means\n",
        "baseline_agg = base[AGG_COLUMNS + [\"AB_mean_score\", \"PTS\"]].mean(numeric_only=True).to_frame(\"mean\").T\n",
        "# Status counts per AB column\n",
        "status_counts = {}\n",
        "for col in AB_COLUMNS:\n",
        "    if col in base.columns:\n",
        "        status_counts[col] = base[col].value_counts().reindex(STATUS_ORDER).fillna(0).astype(int)\n",
        "status_counts_df = pd.DataFrame(status_counts).T\n",
        "\n",
        "print(\"Baseline aggregate means (PASS#/WARN#/FAIL#/PTS, AB_mean_score):\")\n",
        "baseline_agg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute deltas vs baseline for each ablation\n",
        "\n",
        "def compute_deltas_vs_baseline(baseline: pd.DataFrame, variant: pd.DataFrame, label: str) -> pd.DataFrame:\n",
        "    b = baseline[[KEY_COLUMN, \"AB_mean_score\", \"PTS\"] + [f\"{c}__score\" for c in AB_COLUMNS]].copy()\n",
        "    v = variant[[KEY_COLUMN, \"AB_mean_score\", \"PTS\"] + [f\"{c}__score\" for c in AB_COLUMNS]].copy()\n",
        "    merged = b.merge(v, on=KEY_COLUMN, suffixes=(\"_base\", f\"_{label}\"))\n",
        "\n",
        "    # Per-case deltas\n",
        "    merged[f\"delta_AB_mean_score_{label}\"] = merged[f\"AB_mean_score_{label}\"] - merged[\"AB_mean_score_base\"]\n",
        "    merged[f\"delta_PTS_{label}\"] = merged[f\"PTS_{label}\"] - merged[\"PTS_base\"]\n",
        "    for c in AB_COLUMNS:\n",
        "        merged[f\"delta_{c}__score_{label}\"] = merged[f\"{c}__score_{label}\"] - merged[f\"{c}__score_base\"]\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "deltas = {}\n",
        "base_df = scored[\"baseline\"].copy()\n",
        "for label in [\"no_lint\", \"no_tests\", \"no_playwright\"]:\n",
        "    deltas[label] = compute_deltas_vs_baseline(base_df, scored[label], label)\n",
        "\n",
        "# Aggregate mean deltas per ablation\n",
        "mean_deltas = []\n",
        "for label, df in deltas.items():\n",
        "    row = {\n",
        "        \"ablation\": label,\n",
        "        \"mean_delta_AB_mean_score\": df[f\"delta_AB_mean_score_{label}\"].mean(),\n",
        "        \"mean_delta_PTS\": df[f\"delta_PTS_{label}\"].mean(),\n",
        "    }\n",
        "    for c in AB_COLUMNS:\n",
        "        row[f\"mean_delta_{c}__score\"] = df[f\"delta_{c}__score_{label}\"].mean()\n",
        "    mean_deltas.append(row)\n",
        "\n",
        "mean_deltas_df = pd.DataFrame(mean_deltas)\n",
        "mean_deltas_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: mean deltas and worst-case drops\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Barplot of mean delta AB_mean_score and PTS\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sns.barplot(data=mean_deltas_df, x=\"ablation\", y=\"mean_delta_AB_mean_score\", ax=axes[0], palette=\"Set2\")\n",
        "axes[0].axhline(0, color=\"gray\", linewidth=1)\n",
        "axes[0].set_title(\"Mean Δ AB_mean_score vs baseline\")\n",
        "axes[0].set_ylabel(\"Δ score (PASS=1, WARN=0.5, FAIL=0)\")\n",
        "\n",
        "sns.barplot(data=mean_deltas_df, x=\"ablation\", y=\"mean_delta_PTS\", ax=axes[1], palette=\"Set2\")\n",
        "axes[1].axhline(0, color=\"gray\", linewidth=1)\n",
        "axes[1].set_title(\"Mean Δ PTS vs baseline\")\n",
        "axes[1].set_ylabel(\"Δ PTS\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identify worst-case drops per ablation by AB_mean_score and PTS\n",
        "worst_rows = []\n",
        "for label, df in deltas.items():\n",
        "    row_score = df.sort_values(f\"delta_AB_mean_score_{label}\").head(5)[[KEY_COLUMN, f\"delta_AB_mean_score_{label}\"]]\n",
        "    row_score[\"ablation\"] = label\n",
        "    row_pts = df.sort_values(f\"delta_PTS_{label}\").head(5)[[KEY_COLUMN, f\"delta_PTS_{label}\"]]\n",
        "    row_pts[\"ablation\"] = label\n",
        "    worst_rows.append((label, row_score, row_pts))\n",
        "\n",
        "# Show top 5 worst Δ by AB_mean_score and PTS for each ablation\n",
        "for label, w_score, w_pts in worst_rows:\n",
        "    display(pd.DataFrame({\"ablation\": [label]}))\n",
        "    display(w_score.rename(columns={f\"delta_AB_mean_score_{label}\": \"delta_AB_mean_score\"}))\n",
        "    display(w_pts.rename(columns={f\"delta_PTS_{label}\": \"delta_PTS\"}))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
